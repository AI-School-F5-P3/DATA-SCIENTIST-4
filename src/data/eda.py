# -*- coding: utf-8 -*-
"""eda_proyecto_datascience_g4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CNSy4oEWG00Rsh1og2CMzA0fZHjhvfwK

# **Importación de librerias**
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from  colorama  import  Fore
import os

"""# **Importación del Dataset**"""

df_raw = pd.read_csv('data/raw/stroke_dataset.csv')

"""# **Descripción Inicial del Conjunto de Datos y Estructura**"""

# Muestra el número de filas y columnas
print(f"\n{Fore.LIGHTCYAN_EX}Número de filas y columnas:\n{Fore.RESET}")
print(df_raw.shape)

print(f"\n{Fore.LIGHTCYAN_EX}Informacion del dataset:\n{Fore.RESET}")
df_raw.info()

print(f"\n{Fore.LIGHTCYAN_EX}Vista de las primeras filas:\n{Fore.RESET}")
df_raw.head()

# Muestra el número total de duplicados
print(f"\n{Fore.LIGHTCYAN_EX}Número total de duplicados:\n{Fore.RESET}")
print(df_raw.duplicated().sum())

# Información estadística inicial
print(f"\n{Fore.LIGHTCYAN_EX}Información estadística inicial:\n{Fore.RESET}")
df_raw.describe()

"""## Análisis de variables categóricas

##¿Qué hace este código?
***Analiza las columnas categóricas (de tipo object):***

*   Muestra cuántas categorías únicas hay en cada columna.
*   Calcula la moda de cada columna categórica.
*   Muestra la frecuencia de cada categoría.
*   Identifica valores extraños (categorías que solo aparecen una vez).


***Analiza las columnas numéricas que podrían ser categóricas (si tienen pocos valores únicos):***

Calcula el promedio y la moda de estas columnas.
Muestra los valores únicos y verifica si pueden tener algún valor extraño.
"""

# Función para analizar variables categóricas
def analizar_variables_categoricas(df):
    print("Análisis de Variables Categóricas\n")

    # Recorrer todas las columnas categóricas
    for col in df.select_dtypes(include='object').columns:  # Solo para variables categóricas (tipo 'object')
        print(f"Columna: {col}")

        # Contar el número de categorías únicas
        n_categorias = df[col].nunique()
        print(f"Número de categorías: {n_categorias}")

        # Calcular la moda
        moda = df[col].mode()[0]
        print(f"Moda: {moda}")

        # Mostrar categorías y su frecuencia
        print(f"Frecuencia de cada categoría:\n{df[col].value_counts()}\n")

        # Buscar valores extraños o fuera de lo común
        valores_extraños = df[col].value_counts()[df[col].value_counts() == 1]
        if len(valores_extraños) > 0:
            print(f"Valores extraños o inusuales: {valores_extraños}\n")
        else:
            print("No se encontraron valores extraños.\n")

    print("Análisis de Promedios (si alguna columna categórica ha sido convertida a numérica):\n")
    for col in df.select_dtypes(include='number').columns:  # Para columnas numéricas
        if df[col].nunique() < 10:  # Filtrar si tiene pocas categorías
            promedio = df[col].mean()
            moda = df[col].mode()[0]
            print(f"Columna: {col}")
            print(f"Promedio: {promedio}")
            print(f"Moda: {moda}")
            print(f"Valores únicos: {df[col].unique()}\n")
        else:
            print(f"Columna: {col} no parece categórica numérica con pocos valores.\n")

# Llamar a la función para analizar las variables categóricas
analizar_variables_categoricas(df_raw)

"""#Conclusión descripción inicial del dataset:

El dataset tiene 4981 entradas y 11 columnas.
Resumen del análisis inicial:

*   Valores nulos: No hay valores nulos en ninguna columna.
*   Columnas: Hay una combinación de columnas numéricas (edad, hipertensión, nivel de glucosa, IMC) y categóricas (género, estado civil, tipo de trabajo, etc.).

*   ***Estadísticas***:
*   La edad media de los pacientes es de aproximadamente 43 años.
*   El 9.6% de los pacientes tienen hipertensión y el 5.5% sufren de enfermedades cardíacas.
*   El 4.97% de los pacientes han sufrido un ictus.

# **Limpieza de datos**
"""

#comprobar el nombre de las columnas
print (f"\n{Fore.LIGHTCYAN_EX}Nombre de las columnas{Fore.RESET}")
df_raw.columns

#funcion para mostrar gráficos

def save_and_clear_plot(file_name, output_folder="reports/figures/eda_plots"):
    """
    Saves the current plot to a specified folder and then clears the figure.

    Parameters:
    file_name (str): The name of the image file to save (with extension).
    output_folder (str): The folder where the image will be saved (default is "reports/figures/eda_plots").
    """
    # Create the folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)

    # Build the full file path
    output_path = os.path.join(output_folder, file_name)

    # Save the current plot to the specified path
    plt.savefig(output_path)

    # Show the plot (optional)
    plt.show()

    # Clear the current figure to avoid overlapping plots
    plt.clf()

#verificar si hay datos nulos
sns.heatmap(df_raw.isnull())

# Guardar el heatmap y limpiar la figura
save_and_clear_plot("heatmap_valores_nulos.png")

"""### Detección de Outliers Usando el Rango Intercuartílico (IQR)"""

# Calcular Q1 (25%) y Q3 (75%)
Q1 = df_raw['avg_glucose_level'].quantile(0.25)
Q3 = df_raw['avg_glucose_level'].quantile(0.75)
IQR = Q3 - Q1

# Definir los límites para identificar outliers
#Cambiamos 1.5 a 3 para detectar solo los outliers extremos.
lower_bound = Q1 - 3 * IQR 
upper_bound = Q3 + 3 * IQR

# Filtrar los outliers
outliers = df_raw[(df_raw['avg_glucose_level'] < lower_bound) |
                       (df_raw['avg_glucose_level'] > upper_bound)]

print (f"\n{Fore.LIGHTCYAN_EX}Número de outliers:\n{Fore.RESET}{outliers.shape[0]}")

# Vamos a calcular el porcentaje de outliers
total_filas = 4981
outliers_filas = 602

# Calcular el porcentaje
porcentaje_outliers = (outliers_filas / total_filas) * 100
porcentaje_outliers

"""El hecho de haber identificado 602 outliers en la columna AVG Glucose level es una observación significativa, especialmente considerando el tamaño total del dataset (4981 registros). Esto sugiere que aproximadamente el 12% de los registros tienen valores que se consideran atípicos según el criterio del rango intercuartílico (IQR).

Decidimos mantener los outliers en el análisis ya que representan casos de glucosa extremos, los cuales son críticos para comprender cómo estas situaciones afectan de manera significativa la posibilidad de padecer ictus.
La inclusión de los outliers es esencial para el desarrollo de un modelo predictivo robusto, capaz de capturar no solo las relaciones lineales, sino también los efectos drásticos que los valores de glucosa pueden tener en la posibilidad de padecer ictus. Esto permitirá que el modelo generalice mejor y prediga con mayor precisión.

Algunas columnas contienen valores categóricos que deben ser convertidos en valores numéricos para el análisis cuantitativo, como calcular la correlación.
"""

# Codificación de variables categóricas utilizando OneHotEncoding

# Revisar las columnas categóricas que necesitan ser codificadas
categorical_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']

# Utilizamos pd.get_dummies para aplicar OneHotEncoding a las columnas categóricas
df_encoded_a = pd.get_dummies(df_raw, columns=categorical_columns, drop_first=True)

# Ver los primeros registros del dataset después de la codificación
df_encoded_a.head()

# Para convertir True/False a 1/0
df_encoded_a = df_encoded_a.astype(int)
df_encoded_a.head()

def encoding_category_data(df_raw):
    # Crear una copia del DataFrame original
    df_encoded_b = df_raw.copy()

    # Codificación de variables categóricas
    df_encoded_b['gender'] = df_encoded_b['gender'].map({'Male': 0, 'Female': 1})
    df_encoded_b['ever_married'] = df_encoded_b['ever_married'].map({'No': 0, 'Yes': 1})
    df_encoded_b['work_type'] = df_encoded_b['work_type'].map({'Govt_job': 0, 'children': 1, 'Self-employed': 2, 'Private': 3})
    df_encoded_b['Residence_type'] = df_encoded_b['Residence_type'].map({'Rural': 0, 'Urban': 1})
    df_encoded_b['smoking_status'] = df_encoded_b['smoking_status'].map({'smokes': 0, 'formerly smoked': 1, 'Unknown': 2, 'never smoked': 3})

    # Llenar los valores que no se pueden mapear
    df_encoded_b.fillna(-1, inplace=True)  # Por ejemplo, usando -1 para valores desconocidos

    return df_encoded_b

# Llamar a la función y mostrar los resultados
df_encoded_b = encoding_category_data(df_raw)
print(df_encoded_b.head())

"""# **Análisis y Visualización de datos**

## **Rangos de edad**
"""

df_encoded_b['age'].unique()
num_unique_ages = len(df_encoded_b['age'].unique())
print(f"Número de edades únicas: {num_unique_ages}")

# Crear un histograma de la columna 'Age'
plt.figure(figsize=(10, 6))
plt.hist(df_encoded_b['age'], bins=num_unique_ages, color='skyblue', edgecolor='white')
plt.title('Distribución de la Edad de los Clientes')
plt.xlabel('Edad')
plt.ylabel('Frecuencia')
plt.grid(True)

# Ruta de la carpeta donde quieres guardar la imagen
output_folder = "reports/figures/eda_plots"
# Crear la carpeta si no existe
os.makedirs(output_folder, exist_ok=True)

# Guardar la imagen en la carpeta especificada
output_path = os.path.join(output_folder, "info_Age.png")
plt.savefig(output_path)

plt.show()

# Crear una copia del DataFrame para no alterarlo
df_age_groups = df_encoded_b.copy()

# Crear los bins y las etiquetas para los grupos de edad
bins = [0, 12, 17, 24, 34, 44, 54, 64, 100]

labels = [
    'Niños\n(<12 años)',
    'Adolescentes\n(12-17 años)',
    'Jóvenes\n(18-24 años)',
    'Adultos Jóvenes\n(25-34 años)',
    'Adultos\n(35-44 años)',
    'Mediana Edad\n(45-54 años)',
    'Mediana Edad Senior\n(55-64 años)',
    'Mayores de 65\n(+65 años)'
]

# Crear una nueva columna 'Age Group' en el DataFrame
df_age_groups['Age Group'] = pd.cut(df_age_groups['age'], bins=bins, labels=labels, right=False)

# Contar el número de ocurrencias en cada grupo de edad
age_group_counts = df_age_groups['Age Group'].value_counts().sort_index()

# Calcular los porcentajes
age_group_percentages = age_group_counts / age_group_counts.sum() * 100

# Crear un gráfico de barras para visualizar la distribución de los grupos de edad
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=age_group_counts.index, y=age_group_counts.values, color='#b3e5fc', width=0.95)

# Añadir el porcentaje sobre cada barra con 2 decimales
for i, p in enumerate(ax.patches):
    ax.annotate(f'{age_group_percentages.iloc[i]:.2f}%',  # Usar iloc para acceder por posición
                (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=10, color='#01579b', xytext=(0, 5),
                textcoords='offset points')

# Cambiar el tamaño de las etiquetas del eje X
for item in ax.get_xticklabels():
    item.set_fontsize(9)  # Cambiar el tamaño de la parte principal
    item.set_linespacing(1.5)  # Ajustar el espaciado entre líneas

# Añadir etiquetas y título al gráfico
plt.title('Distribución por Grupos de Edad', fontsize=20, pad=30)
plt.xlabel('Grupo de Edad', fontsize=12, labelpad=25)
plt.ylabel('Número de Personas', fontsize=12, labelpad=25)

# Ajustar el margen superior para separar el título del gráfico
plt.subplots_adjust(top=0.85)

# Mostrar el gráfico
plt.tight_layout()

# Ruta de la carpeta donde quieres guardar la imagen
output_folder = "reports/figures/eda_plots"
# Crear la carpeta si no existe
os.makedirs(output_folder, exist_ok=True)

# Guardar la imagen en la carpeta especificada
output_path = os.path.join(output_folder, "info_age_group.png")
plt.savefig(output_path)


plt.show()

"""## **Strokes**

Tasas de Strokes por Grupo de Edad
"""

# Calcular la tasa de satisfacción para cada grupo de edad
stroke_by_age = df_age_groups.groupby('Age Group', observed=False)['stroke'].mean() * 100

# Convertir a DataFrame para facilitar el manejo
stroke_by_age = stroke_by_age.reset_index()
stroke_by_age.columns = ['Grupo de Edad', 'Stroke']

import seaborn as sns
import matplotlib.pyplot as plt

# Diccionario de traducción de variables
translation_dict = {
    'Niños\n(<12 años)': ' <12 años',
    'Adolescentes\n(12-17 años)': '12-17 años',
    'Jóvenes\n(18-24 años)': '18-24 años',
    'Adultos Jóvenes\n(25-34 años)': '25-34 años',
    'Adultos\n(35-44 años)': '35-44 años',
    'Mediana Edad\n(45-54 años)': '45-54 años',
    'Mediana Edad Senior\n(55-64 años)': '55-64 años',
    'Mayores de 65\n(+65 años)': '+65 años'
}

# Asegúrate de que 'stroke_by_age' tiene los nombres de los grupos de edad
# según las claves del diccionario 'translation_dict'

plt.figure(figsize=(10, 6))
ax = sns.barplot(x='Grupo de Edad', y='Stroke', data=stroke_by_age, color='#b3e5fc', width=0.95)

# Añadir etiquetas de porcentaje encima de cada barra
for i, row in stroke_by_age.iterrows():
    plt.text(i, row['Stroke'] + 1, f"{row['Stroke']:.1f}%", ha='center', fontsize=10)

# Cambiar las etiquetas del eje X usando el diccionario de traducción
xticks_labels = [translation_dict.get(label.get_text(), label.get_text()) for label in ax.get_xticklabels()]
ax.set_xticklabels(xticks_labels)

# Cambiar el tamaño de las etiquetas del eje X
for item in ax.get_xticklabels():
    item.set_fontsize(10)  # Cambiar el tamaño de las etiquetas
    item.set_linespacing(1.5)  # Ajustar el espaciado entre líneas

plt.title('Padecimiento de Ictus por Grupo de Edad', fontsize=20, pad=30)
plt.xlabel('Grupo de Edad', fontsize=12, labelpad=25)
plt.ylabel('Strokes (%)', fontsize=12, labelpad=25)

# Ajustar el margen superior para separar el título del gráfico
plt.subplots_adjust(top=0.85)

plt.tight_layout()
plt.show()

"""## **Cálculo de Correlaciones**

Determinar la correlación entre cada factor y el padecimiento de ictus para cuantificar la fuerza y la dirección de la relación. Esto nos dará una idea aún más clara de cúan relacionadas están las variables.
"""

# Calcula la matriz de correlación para todas las variables
correlation_matrix = df_encoded_b.corr()

# Mostrar la matriz de correlación en forma de tabla
print(correlation_matrix)

# Opcional: Visualización de la matriz de correlación con un heatmap
plt.figure(figsize=(16, 12))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', cbar=True)
plt.title('Matriz de Correlación Completa')

# Ruta de la carpeta donde quieres guardar la imagen
output_folder = "reports/figures/eda_plots"
# Crear la carpeta si no existe
os.makedirs(output_folder, exist_ok=True)

# Guardar la imagen en la carpeta especificada
output_path = os.path.join(output_folder, "correlation_matrix.png")
plt.savefig(output_path)

plt.show()

"""***Puntos relevantes**

### Variables con Correlación Fuerte con la Satisfacción:

Las correlaciones calculadas entre cada factor y el padecimiento de ictus (stroke) muestra que los factores que se encuentran más relacionados son: age, hypertension, heart_disease, ever_married y avg_glucose_level.

Age (0.25): Tiene una correlación positiva fuerte, sugiriendo que el género es un factor importante frente a contración de ictus.

Indicadores como hypertensión, enfermedades del corazón y avg_glucose_level estan equiparadamente relacionados con la posibilidad de contraer ictus.

###  Variables con Correlaciones entre Sí:
Age y ever_married (0.68): Muestran una correlación positiva alta.


###  Correlaciones Negativas o Cercanas a Cero:
Tipo de residencia no tiene un impacto significativo en esta temática.



### Conclusiones:
De este análisis surge que los factures críticos para el padecimiento de ictus son la edad, hipertensión, enfermedades cardiovasculares y nivel de glucosa. Siendo no tan significativos el tipo de trabajo o la ubicación.
"""

df_encoded_b.info()

# Guardar el DataFrame en un archivo CSV
df_encoded_b.to_csv('data/processed/stroke_dataset_encoded.csv', index=False)

