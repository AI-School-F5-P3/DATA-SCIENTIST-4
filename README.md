# ğŸ¥ Proyecto Data Scientist: Aprendizaje Supervisado

## ğŸ“‹ Planteamiento
El hospital **F5** lleva un tiempo recogiendo datos cruzados que relacionan diversos indicadores de la vida y estado de salud de algunos pacientes frente a la variable de si han sufrido un **ictus** o no lo han hecho. Ahora han puesto esos datos en manos del departamento de anÃ¡lisis de datos para elaborar un prototipo de programa con inteligencia artificial que, de manera desatendida y como criba previa a una consulta con un doctor, pida por lÃ­nea de comandos los datos necesarios y devuelva si el paciente estÃ¡ en riesgo de sufrir un ictus. Para validar el proyecto, serÃ¡ necesario tambiÃ©n un informe de su rendimiento.

## ğŸ“… Plazos
La entrega se realizarÃ¡ el dÃ­a **28 de Octubre de 2024**.

## ğŸ“¦ Condiciones de entrega
Para el dÃ­a de la reuniÃ³n, serÃ¡ necesario entregar:
- El repositorio en **GitHub**, con el trabajo ordenado adecuadamente en ramas y mensajes de commit limpios y claros.
- Un informe de la clasificaciÃ³n explicado que dÃ© cuenta de la capacidad de la IA.
- Overfitting menor al 5%.
- **Trello** y herramientas organizativas usadas.

## ğŸ› ï¸ TecnologÃ­as a usar
- [Scikit-learn](https://scikit-learn.org/)
- [Pandas](https://pandas.pydata.org/)
- [Git](https://git-scm.com/)
- [GitHub](https://github.com/)

## ğŸ“Š Datos
- **Stroke Dataset**

## ğŸ¯ Niveles de Entrega

### **Nivel Esencial:**
- Un modelo de ML funcional que prediga si un paciente estÃ¡ en riesgo de sufrir un ictus.
- AnÃ¡lisis exploratorio de los datos (**EDA**) con grÃ¡ficos y estadÃ­sticas descriptivas.
- Controlar el overfitting, que la diferencia entre las mÃ©tricas de **training** y las de **test** sea inferior a 5 puntos porcentuales.
- AplicaciÃ³n en lÃ­nea de comandos que permita ingresar datos del paciente y devuelva la predicciÃ³n.
- Una soluciÃ³n que productivice el modelo (una aplicaciÃ³n de **Streamlit**, **Gradio**, una **API**, **Dash**, o algo similar).
- Informe del rendimiento del modelo con mÃ©tricas como la **precisiÃ³n**, **recall**, **F1-score** y **AUC-ROC**, ademÃ¡s de un anÃ¡lisis de las caracterÃ­sticas mÃ¡s importantes que influyen en el riesgo de ictus.

### **Nivel Medio:**
- Un modelo de ML con tÃ©cnicas de **ensemble**.
- Uso de tÃ©cnicas de **ValidaciÃ³n Cruzada**.
- Utilizar mÃ©todos para mitigar el efecto de los datos desbalanceados en el modelo.
- OptimizaciÃ³n del modelo escogido con tÃ©cnicas de ajuste de hiperparÃ¡metros (**Optuna**, **Auto Sklearn**, **PyCaret**, etc.).
- Un sistema que monitorice la **performance** del modelo en producciÃ³n.
- Incluir **test unitarios**.

### **Nivel Avanzado:**
- Una versiÃ³n **dockerizada** del programa.
- Guardado en **bases de datos** de los datos recogidos por la aplicaciÃ³n.
- Despliegue en **Cloud** de las soluciones aportadas.
- Implementar un sistema de **tracking** para los experimentos de ML, registrando parÃ¡metros, mÃ©tricas, cÃ³digo fuente y artefactos de cada experimento (usando **MLFlow** o similar).

### **Nivel Experto:**
- Crear un modelo con **redes neuronales**, y comparar su rendimiento con los modelos de ML clÃ¡sicos.
- Sistemas de entrenamiento y despliegue automÃ¡tico de nuevas versiones del modelo (**A/B testing**, **Data Drifting**, **MLOps**).
- En el futuro, tambiÃ©n se quieren utilizar imÃ¡genes, crear un prototipo de clasificador con **redes neuronales convolucionales** utilizando este otro dataset (Keras, PyTorch, etc.).

## ğŸ“ˆ Estructura de Carpetas para el Proyecto
```bash
/proyecto-ictus/
â”‚
â”œâ”€â”€ /data/                  # Carpeta para los datos
â”‚   â”œâ”€â”€ /raw/               # Datos en bruto (sin procesar)
â”‚   â””â”€â”€ /processed/         # Datos procesados
â”‚
â”œâ”€â”€ /models_pkls/           # Modelos entrenados
â”‚   â””â”€â”€ /xgboost/           # Modelo XGBoost
â”‚
â”œâ”€â”€ /notebooks/             # Jupyter Notebooks para anÃ¡lisis exploratorio y prototipos
â”‚   â”œâ”€â”€ eda.ipynb           # Notebook para el anÃ¡lisis exploratorio de datos
â”‚   â””â”€â”€ model_training.ipynb # Notebook para el entrenamiento del modelo
â”‚
â”œâ”€â”€ /src/                   # CÃ³digo fuente del proyecto
â”‚   â”œâ”€â”€ /data/              # CÃ³digo relacionado con la gestiÃ³n de datos
â”‚   â”œâ”€â”€ /features/          # CÃ³digo para la creaciÃ³n de nuevas caracterÃ­sticas
â”‚   â”œâ”€â”€ /models_definition/ # CÃ³digo para la definiciÃ³n y entrenamiento del modelo
â”‚   â”œâ”€â”€ /visualization/      # CÃ³digo para visualizaciones
â”‚   â””â”€â”€ __init__.py         # Hace que la carpeta src sea un paquete Python
â”‚
â”œâ”€â”€ /reports/               # Informes generados
â”‚   â”œâ”€â”€ /figures/           # GrÃ¡ficos y visualizaciones
â”‚   â””â”€â”€ final_report.pdf     # Informe final del proyecto
â”‚
â”œâ”€â”€ /requirements/          # Archivo de requisitos
â”‚   â””â”€â”€ requirements.txt     # LibrerÃ­as necesarias para el proyecto
â”‚
â”œâ”€â”€ /tests/                 # Pruebas unitarias y de integraciÃ³n
â”‚   â”œâ”€â”€ __init__.py         # Hace que la carpeta tests sea un paquete Python
â”‚   â””â”€â”€ test_model.py       # Pruebas para el modelo
â”‚
â”œâ”€â”€ .gitignore               # Archivos y carpetas que Git debe ignorar
â”œâ”€â”€ README.md                # Archivo README del proyecto
â”œâ”€â”€ setup.py                 # Script de instalaciÃ³n (si es necesario)
â””â”€â”€ LICENSE                  # Licencia del proyecto
